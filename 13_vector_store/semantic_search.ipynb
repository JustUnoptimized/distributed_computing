{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search\n",
    "\n",
    "### University of Virginia\n",
    "### DS 7200: Distributed Computing\n",
    "### Last Updated: September 21, 2023\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources \n",
    "\n",
    "https://colab.research.google.com/github/pinecone-io/examples/blob/master/docs/semantic-search.ipynb\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "In this walkthrough we will see how to use Pinecone for semantic search. To begin we must install the required prerequisite libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU \\\n",
    "  protobuf \\\n",
    "  \"pinecone-client[grpc]\"==2.2.1 \\\n",
    "  pinecone-datasets=='0.5.0rc11' \\\n",
    "  sentence-transformers==2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download\n",
    "\n",
    "In this notebook we will skip the data preparation steps as they can be very time consuming and jump straight into it with the prebuilt dataset from *Pinecone Datasets*. If you'd rather see how it's all done, please refer to [this notebook](https://colab.research.google.com/github/pinecone-io/examples/blob/master/search/semantic-search/semantic-search.ipynb).\n",
    "\n",
    "Let's go ahead and download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>values</th>\n",
       "      <th>sparse_values</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240000</th>\n",
       "      <td>515997</td>\n",
       "      <td>[-0.00531694, 0.06937869, -0.0092854, 0.003286...</td>\n",
       "      <td>{'indices': [845, 1657, 13677, 20780, 27058, 2...</td>\n",
       "      <td>{'text': ' Why is a \"law of sciences\" importan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240001</th>\n",
       "      <td>515998</td>\n",
       "      <td>[-0.09243751, 0.065432355, -0.06946959, 0.0669...</td>\n",
       "      <td>{'indices': [2110, 6324, 9754, 13677, 15207, 2...</td>\n",
       "      <td>{'text': ' Is it possible to format a BitLocke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240002</th>\n",
       "      <td>515999</td>\n",
       "      <td>[-0.021924071, 0.032280188, -0.020190848, 0.07...</td>\n",
       "      <td>{'indices': [2110, 4949, 23579, 23758, 27058, ...</td>\n",
       "      <td>{'text': ' Can formatting a hard drive stress ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240003</th>\n",
       "      <td>516000</td>\n",
       "      <td>[-0.120020054, 0.024080949, 0.10693012, -0.018...</td>\n",
       "      <td>{'indices': [22014, 24734, 24773, 25791, 25991...</td>\n",
       "      <td>{'text': ' Are the new Samsung Galaxy J7 and J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240004</th>\n",
       "      <td>516001</td>\n",
       "      <td>[-0.095293395, -0.048446465, -0.017618902, -0....</td>\n",
       "      <td>{'indices': [307, 2110, 5785, 12969, 12971, 13...</td>\n",
       "      <td>{'text': ' I just watched an add for Indonesia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                             values  \\\n",
       "240000  515997  [-0.00531694, 0.06937869, -0.0092854, 0.003286...   \n",
       "240001  515998  [-0.09243751, 0.065432355, -0.06946959, 0.0669...   \n",
       "240002  515999  [-0.021924071, 0.032280188, -0.020190848, 0.07...   \n",
       "240003  516000  [-0.120020054, 0.024080949, 0.10693012, -0.018...   \n",
       "240004  516001  [-0.095293395, -0.048446465, -0.017618902, -0....   \n",
       "\n",
       "                                            sparse_values  \\\n",
       "240000  {'indices': [845, 1657, 13677, 20780, 27058, 2...   \n",
       "240001  {'indices': [2110, 6324, 9754, 13677, 15207, 2...   \n",
       "240002  {'indices': [2110, 4949, 23579, 23758, 27058, ...   \n",
       "240003  {'indices': [22014, 24734, 24773, 25791, 25991...   \n",
       "240004  {'indices': [307, 2110, 5785, 12969, 12971, 13...   \n",
       "\n",
       "                                                 metadata  \n",
       "240000  {'text': ' Why is a \"law of sciences\" importan...  \n",
       "240001  {'text': ' Is it possible to format a BitLocke...  \n",
       "240002  {'text': ' Can formatting a hard drive stress ...  \n",
       "240003  {'text': ' Are the new Samsung Galaxy J7 and J...  \n",
       "240004  {'text': ' I just watched an add for Indonesia...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone_datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('quora_all-MiniLM-L6-bm25')\n",
    "# we drop sparse_values as they are not needed for this example\n",
    "dataset.documents.drop(['metadata'], axis=1, inplace=True)\n",
    "dataset.documents.rename(columns={'blob': 'metadata'}, inplace=True)\n",
    "# we will use 80K rows of the dataset between rows 240K -> 320K\n",
    "dataset.documents.drop(dataset.documents.index[320_000:], inplace=True)\n",
    "dataset.documents.drop(dataset.documents.index[:240_000], inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Index\n",
    "\n",
    "Now the data is ready, we can set up our index to store it.\n",
    "\n",
    "We begin by initializing our connection to Pinecone. To do this we need a [free API key](https://app.pinecone.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pinecone\n",
    "\n",
    "# get api key from app.pinecone.io\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY') or '2edd47fc-a0ec-45d1-9878-27ff09db58e8'\n",
    "# find your environment next to the api key in pinecone console\n",
    "PINECONE_ENV = os.environ.get('PINECONE_ENVIRONMENT') or 'gcp-starter'\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENV\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now* we create a new index called `semantic-search-fast`. It's important that we align the index `dimension` and `metric` parameters with those required by the `MiniLM-L6` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'semantic-search-fast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# only create index if it doesn't exist\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        name=index_name,\n",
    "        dimension=len(dataset.documents.iloc[0]['values']),\n",
    "        metric='cosine'\n",
    "    )\n",
    "    # wait a moment for the index to be fully initialized\n",
    "    time.sleep(1)\n",
    "\n",
    "# now connect to the index\n",
    "index = pinecone.GRPCIndex(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upsert** the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataset.iter_documents(batch_size=100):\n",
    "    index.upsert(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Queries\n",
    "\n",
    "Now that our index is populated we can begin making queries. We are performing a semantic search for *similar questions*, so we should embed and search with another question. Let's begin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"which city has the highest population in the world?\"\n",
    "\n",
    "# create the query vector\n",
    "xq = model.encode(query).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '69331',\n",
       "              'metadata': {'text': \" What's the world's largest city?\"},\n",
       "              'score': 0.7859108,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []},\n",
       "             {'id': '69332',\n",
       "              'metadata': {'text': ' What is the biggest city?'},\n",
       "              'score': 0.72731656,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []},\n",
       "             {'id': '84749',\n",
       "              'metadata': {'text': \" What are the world's most advanced \"\n",
       "                                   'cities?'},\n",
       "              'score': 0.71006715,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []},\n",
       "             {'id': '109231',\n",
       "              'metadata': {'text': ' Where is the most beautiful city in the '\n",
       "                                   'world?'},\n",
       "              'score': 0.6960978,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []},\n",
       "             {'id': '109230',\n",
       "              'metadata': {'text': ' What is the greatest, most beautiful city '\n",
       "                                   'in the world?'},\n",
       "              'score': 0.65822357,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# now query\n",
    "xc = index.query(xq, top_k=5, include_metadata=True)\n",
    "xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79:  What's the world's largest city?\n",
      "0.73:  What is the biggest city?\n",
      "0.71:  What are the world's most advanced cities?\n",
      "0.7:  Where is the most beautiful city in the world?\n",
      "0.66:  What is the greatest, most beautiful city in the world?\n"
     ]
    }
   ],
   "source": [
    "for result in xc['matches']:\n",
    "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64:  What is the biggest city?\n",
      "0.6:  What is the most dangerous city in USA?\n",
      "0.59:  What's the world's largest city?\n",
      "0.59:  What is the most dangerous city in USA? Why?\n",
      "0.58:  What are the world's most advanced cities?\n"
     ]
    }
   ],
   "source": [
    "query = \"which metropolis has the highest number of people?\"\n",
    "\n",
    "# create the query vector\n",
    "xq = model.encode(query).tolist()\n",
    "\n",
    "# now query\n",
    "xc = index.query(xq, top_k=5, include_metadata=True)\n",
    "for result in xc['matches']:\n",
    "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used different terms in our query than that of the returned documents. We substituted **\"city\"** for **\"metropolis\"** and **\"populated\"** for **\"number of people\"**.\n",
    "\n",
    "> Indented block\n",
    "\n",
    "\n",
    "\n",
    "Despite these very different terms and *lack* of term overlap between query and returned documents — we get highly relevant results — this is the power of *semantic search*.\n",
    "\n",
    "You can go ahead and ask more questions above. When you're done, delete the index to save resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
