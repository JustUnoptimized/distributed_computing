{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab: Tuning and Topic Modeling\n",
    "\n",
    "### University of Virginia\n",
    "### DS 7200: Distributed Computing\n",
    "### Last Updated: August 20, 2023\n",
    "\n",
    "---  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justin Lee\n",
    "\n",
    "### jgh2xh\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS**  \n",
    "In this assignment, you will do three things:\n",
    "1) Tune a logistic regression model  \n",
    "2) Label-balance a dataset  \n",
    "3) Run the Topic Modeling notebook, making small tweaks and capturing results  \n",
    "\n",
    "**TOTAL POINTS: 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/10/16 00:48:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/10/16 00:48:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"data preprocessing\") \\\n",
    "    .config(\"spark.executor.memory\", '8g') \\\n",
    "    .config('spark.executor.cores', '4') \\\n",
    "    .config('spark.cores.max', '4') \\\n",
    "    .config(\"spark.driver.memory\",'8g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# update to match your path\n",
    "directory_path = ''\n",
    "full_path_to_file = os.path.join(directory_path, 'breast_cancer_wisconsin.csv')\n",
    "path_to_data = os.path.join(full_path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class = 2 for benign (negative class, 4 for malignant (positive class)\n",
    "target = 'class'\n",
    "positive_label = 4\n",
    "negative_label = 2\n",
    "\n",
    "SEED = 314"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "brca = spark.read.csv(path_to_data, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- clump_thickness: integer (nullable = true)\n",
      " |-- uniformity_cell_size: integer (nullable = true)\n",
      " |-- uniformity_cell_shape: integer (nullable = true)\n",
      " |-- marginal_adhesion: integer (nullable = true)\n",
      " |-- single_epithelial_cell_size: integer (nullable = true)\n",
      " |-- bare_nuclei: string (nullable = true)\n",
      " |-- bland_chromatin: integer (nullable = true)\n",
      " |-- normal_nucleoli: integer (nullable = true)\n",
      " |-- mitoses: integer (nullable = true)\n",
      " |-- class: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "brca.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brca.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|class|count|\n",
      "+-----+-----+\n",
      "|    4|  241|\n",
      "|    2|  458|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute distribution of target variable\n",
    "brca.groupBy(target).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1:  Cross Validate a Logistic Regression Model\n",
    "i) (**4 PTS**) This task has the following requirements:\n",
    "- import necessary modules\n",
    "- use these features as predictors: `clump_thickness`,`uniformity_cell_size`,`uniformity_cell_shape`,`marginal_adhesion`  \n",
    "- `class` is response variable. apply recoding as needed. hint: save as new variable.\n",
    "- use 3 folds in the cross validator object\n",
    "- use BinaryClassificationEvaluator\n",
    "- logistic regression model with `maxIter`=10  \n",
    "- tuning grid with `regParam` values of 0.1 and 0.01\n",
    "- finally, print the average metrics based on each `regParam` value. the attribute `avgMetrics` in the cv model will hold these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import MaxAbsScaler, VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import pyspark.sql.functions as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+---------------------+-----------------+---------------+\n",
      "|clump_thickness|uniformity_cell_size|uniformity_cell_shape|marginal_adhesion|relabeled_class|\n",
      "+---------------+--------------------+---------------------+-----------------+---------------+\n",
      "|              5|                   1|                    1|                1|              0|\n",
      "|              5|                   4|                    4|                5|              0|\n",
      "|              3|                   1|                    1|                1|              0|\n",
      "|              6|                   8|                    8|                1|              0|\n",
      "|              4|                   1|                    1|                3|              0|\n",
      "+---------------+--------------------+---------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------------+-----+\n",
      "|clump_thickness|count|\n",
      "+---------------+-----+\n",
      "|              1|  145|\n",
      "|              6|   34|\n",
      "|              3|  108|\n",
      "|              5|  130|\n",
      "|              9|   14|\n",
      "|              4|   80|\n",
      "|              8|   46|\n",
      "|              7|   23|\n",
      "|             10|   69|\n",
      "|              2|   50|\n",
      "+---------------+-----+\n",
      "\n",
      "+--------------------+-----+\n",
      "|uniformity_cell_size|count|\n",
      "+--------------------+-----+\n",
      "|                   1|  384|\n",
      "|                   6|   27|\n",
      "|                   3|   52|\n",
      "|                   5|   30|\n",
      "|                   9|    6|\n",
      "|                   4|   40|\n",
      "|                   8|   29|\n",
      "|                   7|   19|\n",
      "|                  10|   67|\n",
      "|                   2|   45|\n",
      "+--------------------+-----+\n",
      "\n",
      "+---------------------+-----+\n",
      "|uniformity_cell_shape|count|\n",
      "+---------------------+-----+\n",
      "|                    1|  353|\n",
      "|                    6|   30|\n",
      "|                    3|   56|\n",
      "|                    5|   34|\n",
      "|                    9|    7|\n",
      "|                    4|   44|\n",
      "|                    8|   28|\n",
      "|                    7|   30|\n",
      "|                   10|   58|\n",
      "|                    2|   59|\n",
      "+---------------------+-----+\n",
      "\n",
      "+-----------------+-----+\n",
      "|marginal_adhesion|count|\n",
      "+-----------------+-----+\n",
      "|                1|  407|\n",
      "|                6|   22|\n",
      "|                3|   58|\n",
      "|                5|   23|\n",
      "|                9|    5|\n",
      "|                4|   33|\n",
      "|                8|   25|\n",
      "|                7|   13|\n",
      "|               10|   55|\n",
      "|                2|   58|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = ['clump_thickness', 'uniformity_cell_size', 'uniformity_cell_shape', 'marginal_adhesion']\n",
    "\n",
    "# relabel class\n",
    "relabeled_class_col = F.when(brca['class'] == positive_label, 1).when(brca['class'] == negative_label, 0)\n",
    "labels = 'relabeled_class'\n",
    "brca = brca.withColumn(labels, relabeled_class_col)\n",
    "\n",
    "# Quick look at the predictors\n",
    "brca.select(features + [labels]).show(5)\n",
    "\n",
    "for feat in features:\n",
    "    brca.groupBy(feat).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 3 folds in the cross validator object\n",
    "# use BinaryClassificationEvaluator\n",
    "# logistic regression model with maxIter=10\n",
    "# tuning grid with regParam values of 0.1 and 0.01\n",
    "# finally, print the average metrics based on each regParam value. the attribute avgMetrics in the cv model will hold these. \n",
    "\n",
    "## setup pipeline here\n",
    "# feature transformations\n",
    "# features_scaled = [feat + '_scaled' for feat in features]\n",
    "# maxabs_stages = [MaxAbsScaler(inputCol=feat, outputCol=feat+'_scaled') for feat in features]\n",
    "# maxabs_pipeline = Pipeline(stages=maxabs_stages)\n",
    "# va = VectorAssembler(inputCols=features_scaled, outputCol='features')\n",
    "va = VectorAssembler(inputCols=features, outputCol='features')\n",
    "maxabs = MaxAbsScaler(inputCol='features', outputCol='features_scaled')\n",
    "\n",
    "# model estimation\n",
    "maxiter = 10\n",
    "logreg = LogisticRegression() \\\n",
    "            .setFeaturesCol('features_scaled') \\\n",
    "            .setLabelCol(labels) \\\n",
    "            .setMaxIter(maxiter)\n",
    "# va.transform(brca).select(x).show(5)\n",
    "\n",
    "# stages = [maxabs_pipeline, va, logreg]\n",
    "stages = [va, maxabs, logreg]\n",
    "\n",
    "model_pipeline = Pipeline(stages=stages)\n",
    "\n",
    "## setup param grid\n",
    "reg_params = [0.1, 0.01]\n",
    "param_grid = ParamGridBuilder() \\\n",
    "                .addGrid(logreg.regParam, reg_params) \\\n",
    "                .build()\n",
    "\n",
    "## setup crossvalidator\n",
    "k = 3\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=labels)\n",
    "cv = CrossValidator() \\\n",
    "        .setEstimator(model_pipeline) \\\n",
    "        .setEstimatorParamMaps(param_grid) \\\n",
    "        .setEvaluator(evaluator) \\\n",
    "        .setNumFolds(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 7.866039991378784\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "## fit model\n",
    "t0 = time.time()\n",
    "cv_model = cv.setParallelism(4).fit(brca)\n",
    "# cv_model = cv.fit(brca)\n",
    "print(\"train time:\", time.time() - t0)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regParam: 0.1  --  avg_auroc: 0.9912708515915821\n",
      "regParam: 0.01  --  avg_auroc: 0.9911033300218205\n"
     ]
    }
   ],
   "source": [
    "avg_metrics = cv_model.avgMetrics\n",
    "\n",
    "for reg_param, avg_metric in zip(reg_params, cv_model.avgMetrics):\n",
    "    print(f'regParam: {reg_param}  --  avg_auroc: {avg_metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2:  Balancing a DataFrame with Downsampling  \n",
    "i) (**2 PTS**) Write a function to implement downsampling.  Enter code into the cell containing the `downsample` function.  \n",
    "\n",
    "INPUTS  \n",
    "* df               - Spark dataframe  \n",
    "* target           - string, target variable  \n",
    "* positive_label   - integer, value of positive label  \n",
    "* negative_label   - integer, value of negative label  \n",
    "\n",
    "OUTPUT  \n",
    "balanced spark dataframe  \n",
    "\n",
    "Downsampling = sample from larger class to match smaller class  \n",
    "\n",
    "**Example:**  \n",
    "\n",
    "INITIAL STATE  \n",
    "Smaller class has 100 records  \n",
    "Larger class size has 400 records\n",
    "\n",
    "ACTION  \n",
    "Sample 100 records from larger class, without replacement  \n",
    "Retain all records from smaller class\n",
    "\n",
    "END STATE    \n",
    "This produces a balanced dataset containing 100 records from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(df, target, positive_label=1, negative_label=0, seed=None):\n",
    "    # get counts of pos and neg label\n",
    "    counts = df.groupBy(target).count()\n",
    "    pos_count = counts.filter(F.col(target) == positive_label).first()['count']\n",
    "    neg_count = counts.filter(F.col(target) == negative_label).first()['count']\n",
    "    total = pos_count + neg_count\n",
    "    \n",
    "    # pick larger class and get sampling fraction\n",
    "    if pos_count > neg_count:\n",
    "        larger = positive_label\n",
    "        smaller = negative_label\n",
    "        frac = neg_count / pos_count\n",
    "    else:\n",
    "        larger = negative_label\n",
    "        smaller = positive_label\n",
    "        frac = pos_count / neg_count\n",
    "    \n",
    "    \n",
    "    larger_samples = df.filter(F.col(target) == larger).sample(fraction=frac, seed=seed)\n",
    "    smaller = df.filter(F.col(target) == smaller)\n",
    "    \n",
    "    downsampled_df = smaller.union(larger_samples)\n",
    "    \n",
    "    return downsampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) **(1 PT)** Print the target distribution from this balanced dataset, to show the label counts nearly match.\n",
    "\n",
    "#### IMPORTANT NOTE:\n",
    "Sampling won't produce the exact fraction you request. In order to sample efficiently, Spark uses Bernouilli Sampling. \n",
    "Each row is assigned a probability of being included. If you request a 10% sample, each row individually has a 10% chance of being included but this does not guarantee an exact 10% sample   \n",
    "(it should be close, however)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|class|count|\n",
      "+-----+-----+\n",
      "|    4|  241|\n",
      "|    2|  253|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "down_brca = downsample(brca, target, positive_label=positive_label, negative_label=negative_label, seed=SEED)\n",
    "\n",
    "down_brca.groupBy(target).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3:  Topic Modeling\n",
    "\n",
    "In this exercise, you will run the `topic_modeling.ipynb` notebook and answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) **(1 PT)** For the first headline in the dataset, the code processes it and extracts tokens. Provide a list of the tokens.\n",
    "\n",
    "+-------------+--------------------------------------------------+  \n",
    "|publish_date | headline_text                                     |  \n",
    "+-------------+--------------------------------------------------+  \n",
    "|20030219     | aba decides against community broadcasting licence|  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tokens = [aba, decid, commun, broadcast, licenc]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) **(1 PT)** The code created a count vectorizer and extracted features. \n",
    "\n",
    "`cv = CountVectorizer(inputCol=\"tokens\", outputCol=\"features\", vocabSize=500, minDF=3.0)`\n",
    "\n",
    "The first document had six tokens and the feature vector looked like this:\n",
    "\n",
    "(500, [118, 498], [1.0, 1.0])   \n",
    "\n",
    "Explain why there are only two non-zero elements in this feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The count vectorizer is set to have a vocab size of 500. This means that only two of the tokens extracted from the first document are within the 500 most common tokens found amongst all the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) **(1 PT)** Change the number of topics to 2, rerun LDA, and visualize the topics by showing the topic words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "topic: 0\n",
    "*************************\n",
    "u\n",
    "iraq\n",
    "polic\n",
    "war\n",
    "man\n",
    "sai\n",
    "claim\n",
    "govt\n",
    "plan\n",
    "nsw\n",
    "*************************\n",
    "topic: 1\n",
    "*************************\n",
    "new\n",
    "win\n",
    "call\n",
    "council\n",
    "qld\n",
    "urg\n",
    "world\n",
    "war\n",
    "iraqi\n",
    "rain\n",
    "*************************\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS5110 Spark 3.3",
   "language": "python",
   "name": "ds5110_spark3.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
